{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "creative-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modules.MyTrainer import NILMTrainer\n",
    "from modules.helpers import create_tree_dir, save_report, train_model, display_res\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from modules.MyDataSet import MyChunk, MyChunkList\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-consultation",
   "metadata": {},
   "source": [
    "# Project Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fallen-preference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "/mnt/B40864F10864B450/WorkSpace/PHD/PHD_exps/NewPaper/torch_nilm/output\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "clean = False\n",
    "ROOT = 'output'\n",
    "dev_list = [\n",
    "              #'fridge', \n",
    "            #'washing machine', \n",
    "            'dish washer'\n",
    "           ]\n",
    "mod_list = [\n",
    "#             'SAED',\n",
    "#             'SimpleGru',\n",
    "#             'FFED',\n",
    "#             'FAED',\n",
    "            'SF2P', \n",
    "            'S2P', \n",
    "#             'WGRU',\n",
    "            ]\n",
    "cat_list = ['Cat'+str(x) for x in range(1,5)]\n",
    "tree_levels = {'root': ROOT, 'l1': ['results'], 'l2': dev_list, 'l3': mod_list, 'experiments':cat_list}\n",
    "create_tree_dir(tree_levels=tree_levels, clean=clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-rocket",
   "metadata": {},
   "source": [
    "# Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "earlier-premium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_2_UKDALE_test_2_UKDALE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_PERIOD = 6\n",
    "WINDOW = 50\n",
    "device = 'dish washer'\n",
    "BATCH = 1024\n",
    "\n",
    "EPOCHS = 5\n",
    "ITERATIONS = 3\n",
    "\n",
    "category = 'Cat1'\n",
    "train_house = 2\n",
    "train_set = 'UKDALE'\n",
    "test_set = train_set\n",
    "test_house = train_house\n",
    "\n",
    "experiment_name = 'train_'+ str(train_house) + '_'  + train_set +\\\n",
    "                  '_test_'+ str(test_house) + '_' + test_set\n",
    "\n",
    "model_hparams={\n",
    "              'SimpleGru':{},\n",
    "              'SAED':{'window_size':WINDOW},\n",
    "              'FFED':{},\n",
    "              'WGRU':{'dropout':0.25},\n",
    "              'S2P': {'window_size':WINDOW, 'dropout':0.25},\n",
    "              'SF2P': {'window_size':WINDOW, 'dropout':0.25},\n",
    "              'FAED': {'depth': 2, 'kernel_size':5, 'cnn_dim': 64,\n",
    "                       'input_dim':WINDOW, 'hidden_dim':WINDOW*8, 'dropout':0.25}\n",
    "               }\n",
    "experiment_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-inspector",
   "metadata": {},
   "source": [
    "# TrainLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "material-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementation of torch dataset using NILMTK\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ddc20c7c3eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"2014-02-01\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2014-05-01\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbuilding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_house\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_dataset = MyChunk(path=path, building=building, window_size=WINDOW,\n\u001b[0m\u001b[1;32m      6\u001b[0m                   device=device, dates=dates, sample_period=SAMPLE_PERIOD)\n\u001b[1;32m      7\u001b[0m train_loader = DataLoader(train_dataset, batch_size=BATCH, \n",
      "\u001b[0;32m/mnt/B40864F10864B450/WorkSpace/PHD/PHD_exps/NewPaper/torch_nilm/modules/MyDataSet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, building, device, dates, transform, window_size, test, mmax, sample_period, **load_kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m#get chunk details, but not needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmainchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmainchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_nilm/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "d_name = train_set\n",
    "path = '/mnt/B40864F10864B450/WorkSpace/PHD/PHD_exps/data/{}/{}.h5'.format(d_name,d_name)\n",
    "dates = [\"2014-02-01\",\"2014-05-01\"]\n",
    "building = train_house\n",
    "train_dataset = MyChunk(path=path, building=building, window_size=WINDOW,\n",
    "                  device=device, dates=dates, sample_period=SAMPLE_PERIOD)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, \n",
    "                          shuffle=False, num_workers=8)\n",
    "mmax = train_dataset.mmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-providence",
   "metadata": {},
   "source": [
    "# TestLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = test_set\n",
    "path = '/mnt/B40864F10864B450/WorkSpace/PHD/PHD_exps/data/{}/{}.h5'.format(d_name,d_name)\n",
    "dates = [\"2014-09-01\",\"2014-10-01\"]\n",
    "building = test_house\n",
    "test_dataset = MyChunk(path=path, building=building, window_size=WINDOW,\n",
    "                  device=device, dates=dates, test=True, mmax=train_dataset.mmax, sample_period=SAMPLE_PERIOD)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, \n",
    "                          shuffle=False, num_workers=8)\n",
    "ground = test_dataset.meterchunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-paper",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-death",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_params={'device':device,\n",
    "             'mmax':mmax,\n",
    "             'groundtruth':ground}\n",
    "for model_name in mod_list:\n",
    "    print('#'*40)\n",
    "    print('MODEL: ', model_name)\n",
    "    print('#'*40)\n",
    "    for iteration in range(1,ITERATIONS+1):\n",
    "        print('#'*20)\n",
    "        print('Iteration: ', iteration)\n",
    "        print('#'*20)\n",
    "        m_hparams, results, preds = train_model(model_name=model_name,\n",
    "                                                model_hparams=model_hparams[model_name],\n",
    "                                                train_loader=train_loader, \n",
    "                                                test_loader=test_loader,\n",
    "                                                epochs=EPOCHS,\n",
    "                                                eval_params=eval_params)\n",
    "        save_report(ROOT, model_name, device, category,experiment_name,\n",
    "                    iteration, results, preds, ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in mod_list:\n",
    "    print('#'*40)\n",
    "    print('MODEL: ', model_name)\n",
    "    print('#'*40)\n",
    "    display_res(ROOT, model_name, device, category,experiment_name,\n",
    "                1,low_lim=4800, upper_lim=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
